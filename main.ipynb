{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEe1hEH9V8cB"
      },
      "source": [
        "# **EECS 4214 Final Project**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m-BI84ny9IO"
      },
      "source": [
        "## Section 1\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### **What is the existing state-of-the-art?**\n",
        "\n",
        "When we examine the current 5th-gen cellular networks, there are some key aspects that characterize this technology. Firstly, currently beamforming is employed. Beamforming means that wireless signals are directed towards User Equipment, thus, directional signal transmission is being employed. Also, the MIMO (Multiple-Input Multiple-Output) technique is used, which is a technology that employs the usage of multiple receivers and transmitters to transfer a larger amount of data. Also, large reflecting surfaces are used to assist signal propogation to enable the signal to combine at receiver coherently. Additionaly, millimeter-wave capabilites are also present which allows for communication on a higher band, which is suitable for densely populated areas however with shorter ranges.\n",
        "\n",
        "Currently, there are issues with beamforming optamality due to small channel coherence, convexity and limited CSI (Channel State Information). To tackle this problem, approaches like hierarchical codebook beamforming and deep-learning approaches have been availed, however, these approaches do not serve as a dignified substitue to having good CSI.\n",
        "\n",
        "\n",
        "### **What are the contributions of the author and why they are different from the existing literature?**\n",
        "The contributions of the author are to use deep-learning models to properly predict beamforms using LiDAR. Other contributors use deep-learning models based on gated reccurence units (GRUs) that the author claims do not accurately predict the beamforms. The author claims that a top-1 accuracy of 57% was reached using GRU based models. Instead, this author wants to use a long-sort term memory (LSTM) based model which picks an optimal beam out of a codebook to help predict future beams.\n",
        "\n",
        "\n",
        "### **What is the research problem and the significance of the research?**\n",
        "Data transmission on a broadcast signal like normal 4G and 3G signals entaila an scaling problem when dealing with wider bandiwth and higher frequency signals. For this, 5G comes up with the technology to direct a concetrated tranasmission signal instead of broadcasting. This is called \"beamforming\". Neverthelss, this technology implies that understanding of the state of the reciever and the channel in which the signal is carried upon. For this, the research presents a deep learning algorithm based on the input of a LiDAR camera to find the most optimal beamform prediction for the receiver.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzWscpyNzrGp"
      },
      "source": [
        "## Section 2\n",
        "\n",
        "---\n",
        "\n",
        "## **Explain the system model and assumptions.**\n",
        "The system uses a base station as the transmitter and 'user equipment' as the reciever. The signal recieved at the UE can be represented as a function of the channel h[t], the beamform vector f[t], and the transmitted pilot 's'. It also takes in account additive Gaussian white noise (AGWN) represented by n[t]. The base station (BS) which has LiDAR technology, is able to scan the environment and read the angle 'Î¸' and distance 'd' of an object. These measurements are saved for every time block 'k'. This data is then passed through a SCR filter that removes any 'outlier' data and shrinks the dataset down. It is then put through an 'embedding layer' which converts the dataset into something that the LSTM model can process. After the LSTM model processes the data, an optimization algorithm then converts the data into a regression result. This data is then processed more by rounding the numbers and making them all positive.\n",
        "\n",
        "## **Explain the considered optimizations problem.**\n",
        "Other contributions to this problem struggle to maximize the signal-to-noise ratio (SNR) at the UE. The author proposes that their solution should find the optimal beamforming vector out of a codebook which can help maximize the SNR. With LiDAR, we can predict the next optimal beamforming vector out of a pre-optimized codebook which can yield more accurate results and give a better SNR value.\n",
        "\n",
        "## **Identify the objective, constraints, an optimization variable**\n",
        "- Objective:\n",
        "The main objective of this research is to utilize the LiDAR data to\n",
        "predict the future optimal beamforming vector out (distance, angle) of a set\n",
        "of pre-optimized beam steering codebook.\n",
        "Constraints:\n",
        "\n",
        "- Constraints:\n",
        "  \n",
        "\n",
        "- Optimization Variable:\n",
        "The paper mentioned on maximatizing the following expression.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Where, h represents the channel/medium in which the beamed data would be travelling around and f representing a beamformeing vector from a pre-optimized beam steering codebook. These two are the only variables as the denominator is just the varaince of the variables. Moreover, as one can not always understand the channel in which data is being sent, especially when the channel is the everything surrounding the TX and RX as in the case of wireless communication, the variable to be optimzed is f. Therefore, the LSTM must predict an ideal beamforming vector for the data sent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNNT0qmSz-B9"
      },
      "source": [
        "# Section 3 - Code\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwy-fZHjBFnc"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADDdfRgoVulh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,roc_auc_score,confusion_matrix,accuracy_score,f1_score,roc_curve\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.layers import Activation, Dense, Dropout, Embedding, LSTM\n",
        "import re\n",
        "from IPython.display import display\n",
        "import os\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import io\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import imdb\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import scipy\n",
        "import csv\n",
        "\n",
        "random.seed(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpUF1BkXrBWX",
        "outputId": "fbe9b7f5-e7ef-4e56-87a5-aa652e10cf8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHGrnrbqetV7"
      },
      "source": [
        "## Acquiring the 6G dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcT1J5NX0WMV",
        "outputId": "23a56edc-ffba-4f2f-b824-78d7efa2b378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********* Training Dataset *********\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2831 entries, 0 to 2830\n",
            "Data columns (total 5 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   index              2831 non-null   object\n",
            " 1   unit1_lidar_1      2831 non-null   object\n",
            " 2   unit1_lidar_SCR_1  2831 non-null   object\n",
            " 3   unit1_pwr_1        2831 non-null   object\n",
            " 4   beam_index_1       2831 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 110.7+ KB\n",
            "********* Testing Dataset *********\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 437 entries, 0 to 436\n",
            "Data columns (total 5 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   index              437 non-null    object\n",
            " 1   unit1_lidar_1      437 non-null    object\n",
            " 2   unit1_lidar_SCR_1  437 non-null    object\n",
            " 3   unit1_pwr_1        437 non-null    object\n",
            " 4   beam_index_1       437 non-null    object\n",
            "dtypes: object(5)\n",
            "memory usage: 17.2+ KB\n"
          ]
        }
      ],
      "source": [
        "directory_path = '/content/drive/MyDrive/EECS 4214/Scenario8/Scenario8/development_dataset/'\n",
        "file_path_test = directory_path + 'scenario8_dev_test.csv'\n",
        "file_path_train = directory_path +  'scenario8_dev_train.csv'\n",
        "\n",
        "def retrieve_dataset(file_path):\n",
        "  with open(file_path, 'r') as file:\n",
        "    # Read the first line to extract headers\n",
        "    headers = file.readline().strip().split(',')\n",
        "\n",
        "    # Read the remaining lines and store them in a list\n",
        "    data_lines = file.readlines()\n",
        "\n",
        "  # Convert the list of data lines into a DataFrame\n",
        "  df = pd.DataFrame([line.strip().split(',') for line in data_lines], columns=headers)\n",
        "\n",
        "  return df\n",
        "\n",
        "df_test = retrieve_dataset(file_path_test)\n",
        "df_train = retrieve_dataset(file_path_train)\n",
        "\n",
        "print(\"********* Training Dataset *********\")\n",
        "df_train.info()\n",
        "print(\"********* Testing Dataset *********\")\n",
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEXk0JpHdpUV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "for i in range(len(df_train)):\n",
        "  #concat the scr file path to root\n",
        "  mat_directory = directory_path[:-1] + df_train.iloc[i,2][1:]\n",
        "  #load all matlab variable data\n",
        "  mat_data = scipy.io.loadmat(mat_directory)\n",
        "  #extract the 'data' variable from the matlab data\n",
        "  lidarData = mat_data['data'].transpose()\n",
        "  #reshape the data to 1 sample, with 216 time steps and 2 features (distance and angle)\n",
        "  lidarData = lidarData.reshape(2,216)\n",
        "  x_train.append(lidarData)\n",
        "  y_train.append(int(df_train.iloc[i,4]))\n",
        "\n",
        "\n",
        "for i in range(len(df_test)):\n",
        "  #concat the scr file path to root\n",
        "  mat_directory = directory_path[:-1] + df_test.iloc[i,2][1:]\n",
        "  #load all matlab variable data\n",
        "  mat_data = scipy.io.loadmat(mat_directory)\n",
        "  #extract the 'data' variable from the matlab data\n",
        "  lidarData = mat_data['data'].transpose()\n",
        "  #reshape the data to 1 sample, with 216 time steps and 2 features (distance and angle)\n",
        "  lidarData = lidarData.reshape(2, 216)\n",
        "  x_test.append(lidarData)\n",
        "  y_test.append(int(df_test.iloc[i,4]))\n",
        "\n",
        "\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27mgTxS0dzTn"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.reshape(len(df_train), 1, 1)\n",
        "y_test = y_test.reshape(len(df_test), 1, 1)\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, activation= softplus, kernel_regularizer=regularizers.L2(0.01),\n",
        "    bias_regularizer=regularizers.L2(0.01),\n",
        "    activity_regularizer=regularizers.L2(0.01), input_shape = (2,216)))\n",
        "model.add(Dense(10))\n",
        "#model.add(Dropout(0.591))\n",
        "\n",
        "def my_acc(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "\n",
        "model.compile(optimizer= Nadam(), loss=LogCosh(), metrics = my_acc )\n",
        "\n",
        "#epochs derived from article\n",
        "history = model.fit(x_train, y_train, batch_size = 1 , epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leW-51aH2GwD"
      },
      "outputs": [],
      "source": [
        "def get_data_values(df):\n",
        "  for idx, cell in enumerate(df):\n",
        "      if isinstance(cell, str):\n",
        "          if cell.startswith('.'):\n",
        "              # Delete the first character (period) and concatenate with another string\n",
        "              new_value = directory_path[:-1] + cell[1:]\n",
        "              # Update the cell with the modified value\n",
        "              df.at[idx] = new_value\n",
        "\n",
        "  # load .mat files\n",
        "  for idx, cell in enumerate(df):\n",
        "      if isinstance(cell, str):  # Check if the cell contains a string\n",
        "          # Load data from the .mat file and add it to the same cell\n",
        "          df.at[idx] = load_data_from_mat(cell)\n",
        "          # kernel_temp = pd.DataFrame(df.at[idx])\n",
        "          # kernel_temp.info()\n",
        "\n",
        "  return df\n",
        "\n",
        "def load_data_from_mat(mat_file_path):\n",
        "    mat_data = scipy.io.loadmat(mat_file_path)\n",
        "\n",
        "    return mat_data['data']\n",
        "\n",
        "\n",
        "\n",
        "df_train_CSR = get_data_values(df_train[\"unit1_lidar_SCR_1\"])\n",
        "# print(df_train_CSR)\n",
        "\n",
        "\n",
        "# df_train_CSR = [{'distance': entry[0], 'angle': entry[1]} for entry in df_train_CSR]\n",
        "# df_train_CSR = pd.DataFrame(df_train_CSR)\n",
        "\n",
        "df_test_CSR = get_data_values(df_test[\"unit1_lidar_SCR_1\"])\n",
        "# df_test_CSR = [{'distance': entry[0], 'angle': entry[1]} for entry in df_test_CSR]\n",
        "# df_test_CSR =  pd.DataFrame(df_test_CSR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "G8p-xbIlgZGN",
        "outputId": "83804171-5650-425f-91e9-2cb3028311ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     index                            unit1_lidar_1  \\\n",
            "0        1  ./unit1/lidar_data/Lidar_data_27191.mat   \n",
            "1        2   ./unit1/lidar_data/Lidar_data_4033.mat   \n",
            "2        3  ./unit1/lidar_data/Lidar_data_10667.mat   \n",
            "3        4  ./unit1/lidar_data/Lidar_data_22645.mat   \n",
            "4        5  ./unit1/lidar_data/Lidar_data_11896.mat   \n",
            "...    ...                                      ...   \n",
            "2826  2827  ./unit1/lidar_data/Lidar_data_26231.mat   \n",
            "2827  2828  ./unit1/lidar_data/Lidar_data_10668.mat   \n",
            "2828  2829  ./unit1/lidar_data/Lidar_data_19252.mat   \n",
            "2829  2830  ./unit1/lidar_data/Lidar_data_22630.mat   \n",
            "2830  2831  ./unit1/lidar_data/Lidar_data_11569.mat   \n",
            "\n",
            "                                      unit1_lidar_SCR_1  \\\n",
            "0     [[0.0, -2.094122394697571], [0.0, -2.072578486...   \n",
            "1     [[0.0, -2.094395102393195], [0.0, -2.079396179...   \n",
            "2     [[0.0, 0.0], [0.0, -2.0755782713951314], [0.0,...   \n",
            "3     [[0.0, -2.0908499023500813], [0.0, -2.07148765...   \n",
            "4     [[0.0, -2.0913953177413305], [0.0, -2.07257848...   \n",
            "...                                                 ...   \n",
            "2826  [[0.0, 0.0], [0.0, -2.0755782713951314], [0.0,...   \n",
            "2827  [[0.0, 0.0], [0.0, -2.0802143022207416], [0.0,...   \n",
            "2828  [[0.0, -2.0908499023500813], [0.0, -2.07203307...   \n",
            "2829  [[0.0, -2.086213871524472], [0.0, -2.071487655...   \n",
            "2830  [[0.0, 0.0], [0.0, -2.082941379176983], [0.0, ...   \n",
            "\n",
            "                                    unit1_pwr_1 beam_index_1  \n",
            "0     ./unit1/mmWave_data/mmWave_power_4025.txt           63  \n",
            "1      ./unit1/mmWave_data/mmWave_power_572.txt           26  \n",
            "2     ./unit1/mmWave_data/mmWave_power_1519.txt           63  \n",
            "3     ./unit1/mmWave_data/mmWave_power_3349.txt           47  \n",
            "4     ./unit1/mmWave_data/mmWave_power_1695.txt            2  \n",
            "...                                         ...          ...  \n",
            "2826  ./unit1/mmWave_data/mmWave_power_3874.txt           49  \n",
            "2827  ./unit1/mmWave_data/mmWave_power_1520.txt           62  \n",
            "2828  ./unit1/mmWave_data/mmWave_power_2829.txt           37  \n",
            "2829  ./unit1/mmWave_data/mmWave_power_3334.txt           16  \n",
            "2830  ./unit1/mmWave_data/mmWave_power_1651.txt           21  \n",
            "\n",
            "[2831 rows x 5 columns]\n",
            "14\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 2831 into shape (14,432)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-26361a76a253>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Reshape the array to have 432 elements per row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mreshaped_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train_CSR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m432\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create a DataFrame from the reshaped array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2831 into shape (14,432)"
          ]
        }
      ],
      "source": [
        "\n",
        "# Convert the array of arrays into a numpy array\n",
        "df_train_CSR = np.array(df_train_CSR)\n",
        "print(df_train)\n",
        "# Calculate the number of rows in the reshaped array\n",
        "num_rows = -(-len(df_train_CSR)//216)\n",
        "\n",
        "print(num_rows)\n",
        "\n",
        "# Reshape the array to have 432 elements per row\n",
        "reshaped_array = df_train_CSR.reshape(num_rows, 432)\n",
        "\n",
        "# Create a DataFrame from the reshaped array\n",
        "df_train_CSR = pd.DataFrame(reshaped_array)\n",
        "\n",
        "print(df_train_CSR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p9KYItstWQx8",
        "outputId": "2dcc0dd4-e254-44d4-edf8-28a6dfbed029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.00000000e+00 -2.09412239e+00]\n",
            " [ 0.00000000e+00 -2.07257849e+00]\n",
            " [ 0.00000000e+00 -2.06030664e+00]\n",
            " [ 0.00000000e+00 -2.04612584e+00]\n",
            " [ 0.00000000e+00 -2.02730901e+00]\n",
            " [ 0.00000000e+00 -2.01231009e+00]\n",
            " [ 0.00000000e+00 -1.98558473e+00]\n",
            " [ 0.00000000e+00 -1.97113122e+00]\n",
            " [ 0.00000000e+00 -1.95176898e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00 -1.72214910e+00]\n",
            " [ 0.00000000e+00 -1.70687747e+00]\n",
            " [ 0.00000000e+00 -1.68042482e+00]\n",
            " [ 0.00000000e+00 -1.66597131e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 8.12825651e+00 -1.14319066e+00]\n",
            " [ 8.12825651e+00 -1.12900986e+00]\n",
            " [ 8.22985972e+00 -1.11046574e+00]\n",
            " [ 8.36533066e+00 -1.09546681e+00]\n",
            " [ 8.53466934e+00 -1.06901417e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 1.36825651e+01 -9.42750504e-01]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00 -6.74406131e-01]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00 -5.75958653e-01]\n",
            " [ 0.00000000e+00 -5.54414745e-01]\n",
            " [ 0.00000000e+00 -5.42415607e-01]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00 -5.09145268e-01]\n",
            " [ 0.00000000e+00 -4.93873637e-01]\n",
            " [ 0.00000000e+00 -4.67148283e-01]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00 -4.19151728e-01]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00 -3.72791420e-01]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00 -2.84434127e-01]\n",
            " [ 0.00000000e+00 -2.72162280e-01]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00 -1.63079202e-01]\n",
            " [ 0.00000000e+00 -1.48625694e-01]\n",
            " [ 0.00000000e+00 -1.28990740e-01]\n",
            " [ 4.43667335e+00 -1.14537232e-01]\n",
            " [ 0.00000000e+00 -1.02265386e-01]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00 -5.37234160e-02]\n",
            " [ 0.00000000e+00 -2.69980619e-02]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  7.90852317e-03]\n",
            " [ 0.00000000e+00  2.23620310e-02]\n",
            " [ 0.00000000e+00  3.43611696e-02]\n",
            " [ 0.00000000e+00  5.64504930e-02]\n",
            " [ 0.00000000e+00  6.87223393e-02]\n",
            " [ 0.00000000e+00  8.29031395e-02]\n",
            " [ 7.17995992e+00  1.01719970e-01]\n",
            " [ 0.00000000e+00  1.16991601e-01]\n",
            " [ 0.00000000e+00  1.35808432e-01]\n",
            " [ 0.00000000e+00  1.58170463e-01]\n",
            " [ 0.00000000e+00  1.77805418e-01]\n",
            " [ 0.00000000e+00  1.92258925e-01]\n",
            " [ 0.00000000e+00  2.04530772e-01]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  4.82692621e-01]\n",
            " [ 0.00000000e+00  4.97146129e-01]\n",
            " [ 0.00000000e+00  5.09417975e-01]\n",
            " [ 0.00000000e+00  5.23871483e-01]\n",
            " [ 0.00000000e+00  5.43233730e-01]\n",
            " [ 0.00000000e+00  5.57959945e-01]\n",
            " [ 0.00000000e+00  5.84412592e-01]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  1.07283207e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00]]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'Y' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9a148803763b>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# Target data (all but the first element)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape X for LSTM input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape y for LSTM input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
          ]
        }
      ],
      "source": [
        "# Sample dataset\n",
        "dataset = df_train_CSR\n",
        "\n",
        "# Convert the dataset to a numpy array\n",
        "dataset_array = np.array(dataset)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(len(df_train_CSR), 1)))\n",
        "model.add(Dense(2))  # Assuming 2 output values per time step\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the LSTM model for each row in the dataset\n",
        "for row in dataset_array:\n",
        "    X = row[:-1]  # Input data (all but the last element)\n",
        "    y = row[1:]   # Target data (all but the first element)\n",
        "    X = np.array(X).reshape(1, X.shape[1], X.shape[2])  # Reshape X for LSTM input\n",
        "    y = np.array(y).reshape(1, y.shape[1], y.shape[2])  # Reshape y for LSTM input\n",
        "    model.fit(X, y, epochs=100, verbose=0)  # Train the model for each row\n",
        "\n",
        "# Make predictions (not shown in this example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x1EQBe-KMjYc",
        "outputId": "f776a8fc-31fc-421f-9c03-91fd97ffd4f4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train_CSR\",\n  \"rows\": 2831,\n  \"fields\": [\n    {\n      \"column\": \"distance\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"angle\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train_CSR"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0042e0ee-12d0-4809-aeb0-4a77f3670207\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>distance</th>\n",
              "      <th>angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.0, -2.094122394697571]</td>\n",
              "      <td>[0.0, -2.072578486743266]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.0, -2.094395102393195]</td>\n",
              "      <td>[0.0, -2.0793961791338695]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.0, 0.0]</td>\n",
              "      <td>[0.0, -2.0755782713951314]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.0, -2.0908499023500813]</td>\n",
              "      <td>[0.0, -2.0714876559607696]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.0, -2.0913953177413305]</td>\n",
              "      <td>[0.0, -2.072578486743266]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0042e0ee-12d0-4809-aeb0-4a77f3670207')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0042e0ee-12d0-4809-aeb0-4a77f3670207 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0042e0ee-12d0-4809-aeb0-4a77f3670207');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-797aca5f-c900-4480-8ead-1e389dc18a9c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-797aca5f-c900-4480-8ead-1e389dc18a9c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-797aca5f-c900-4480-8ead-1e389dc18a9c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                     distance                       angle\n",
              "0   [0.0, -2.094122394697571]   [0.0, -2.072578486743266]\n",
              "1   [0.0, -2.094395102393195]  [0.0, -2.0793961791338695]\n",
              "2                  [0.0, 0.0]  [0.0, -2.0755782713951314]\n",
              "3  [0.0, -2.0908499023500813]  [0.0, -2.0714876559607696]\n",
              "4  [0.0, -2.0913953177413305]   [0.0, -2.072578486743266]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train_CSR.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NqLPQjCMNn-",
        "outputId": "4d084e16-704f-437d-f7d9-5164cd1e27bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2831 entries, 0 to 2830\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   distance  2831 non-null   object\n",
            " 1   angle     2831 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 44.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df_train_CSR.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmMpXAoR2DHS"
      },
      "source": [
        "### Swapping .mat files for data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaisZNdgxTyE"
      },
      "source": [
        "## Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8EZ1WRIxXPM"
      },
      "outputs": [],
      "source": [
        "# Define a function for embedding layer\n",
        "def embedding_layer(data, embedding_dim):\n",
        "    reshaped_data = data.reshape(-1, embedding_dim)\n",
        "    return reshaped_data\n",
        "\n",
        "# Define the preprocessing pipeline (SRC is already given in the dataset)\n",
        "preprocessing_pipeline = Pipeline([\n",
        "    ('embedding', embedding_layer),       # Embedding Layer\n",
        "    ('scaler', StandardScaler())          # StandardScaler\n",
        "])\n",
        "\n",
        "# Set embedding dimension\n",
        "embedding_dim = 10\n",
        "\n",
        "# Fit-transform the data using the preprocessing pipeline\n",
        "processed_data = preprocessing_pipeline.fit_transform(time_series_data, embedding_dim=embedding_dim)\n",
        "\n",
        "# 'processed_data' contains the pre-processed time series data ready to be used with an LSTM layer."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
